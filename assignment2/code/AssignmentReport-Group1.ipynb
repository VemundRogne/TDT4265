{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report - Group 150 - Vemund Rogne and Kristian Brudeli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2c)\n",
    "![](experiments/2c.png) \n",
    "\n",
    "We see that the network achieves validation accuracy of ~98.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2d)\n",
    "\n",
    "The network has parameters according to\n",
    "\n",
    "$$\n",
    "n_{parameters} = (n_{inputs} + 1) \\cdot n_{hidden} + n_{hidden} \\cdot n_{out}\n",
    "$$\n",
    "\n",
    "Where the term \"+1\" comes from the bias trick. In our case, this equals\n",
    "\n",
    "$$\n",
    "n_{parameters} = (784 + 1) \\cdot 64 + 64 \\cdot 10 = 50880\n",
    "$$\n",
    "\n",
    "Our network has 50880 parameters. This may also be verified through counting the number of elements in the arrays in `model.ws` in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that with each trick added, the training improves. Note that early stopping is activated, so the x-axis has a different number of training steps per run. \n",
    "\n",
    "### Task 3a)\n",
    "![](experiments/3a.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3b)\n",
    "\n",
    "![](experiments/3b.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3c)\n",
    "![](experiments/3c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "\n",
    "We see that the network performs slightly worse than the final network with the improvements from task 3. WhThe learning rate was kept at 0.02.ile the previous network achieved a validation accuracy of \\~TK%, this network achieves a validation accuracy of \\~TK%. This means that it makes classification errors TK as often. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "The network with more hidden units (128) has a lslightly higherower accuracy than both the network from task 3 and the one from task 4a). It achieves an accuracy of ~ However, the wall-clock time of training was slightly higher because of the larger amount of parameters to optimize in the network. This is not apparent in the graph, which only considers the training steps.TK%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4d)\n",
    "Using 59 hidden units in both layers, we get approximately the same amount of parameters. In the previous layer we had 50880 parameters, while here we have:\n",
    "\n",
    "$$\n",
    "n_{parameters} = (784 + 1) \\cdot 59 + 59 \\cdot 59 + 59 \\cdot 10 = 50386 \\approx 50880\n",
    "$$\n",
    "\n",
    "![](task4d_train_val_loss.png)\n",
    "![](task4d_train_val_accuracy.png)\n",
    "\n",
    "TK \n",
    "The network showed validation accuracy of 95%, TK which is worse than the previous network (which ended up with validation accuracy of TK%). It seems that the deeper network does not give better performance.TK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4e)\n",
    "The network performs worse when using 10 layers of 64 hidden units. The accuracy stays around TK during training.\n",
    "\n",
    "We assume that the reason for the degradation of performance is that the model is too complex, meaning that the additional layers does not improve its ability to learn meaningful features for classification.\n",
    "\n",
    "The network may also run into the _vanishing gradient problem_. This may happen if the elements of the gradients get smaller and smaller when backpropagating the gradients by multiplying small numbers many times through the chain rule. This may make the early layers of the network train very slowly."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b9eeacecb07f391d7d04b1cbad016fa3bf3b7137f2514df4e1830cf167fc4550"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
